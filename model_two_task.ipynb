{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install speechbrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2xxj-Oqfelf",
        "outputId": "fd1ddfd5-da8b-4738-cd87-e100fc585896"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting speechbrain\n",
            "  Downloading speechbrain-1.0.0-py3-none-any.whl (760 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.1/760.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperpyyaml (from speechbrain)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from speechbrain) (24.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.11.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain) (0.1.99)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from speechbrain) (4.66.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from speechbrain) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->speechbrain)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (6.0.1)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->speechbrain) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->speechbrain) (1.3.0)\n",
            "Installing collected packages: ruamel.yaml.clib, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ruamel.yaml, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, hyperpyyaml, speechbrain\n",
            "Successfully installed hyperpyyaml-1.2.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 speechbrain-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install datasets -U\n",
        "!pip install librosa\n",
        "!pip install jiwer"
      ],
      "metadata": {
        "id": "IwORGsfYf-qZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from speechbrain.inference.speaker import EncoderClassifier\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Compose\n",
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor, AutoFeatureExtractor, WhisperModel"
      ],
      "metadata": {
        "id": "t5T6u3TCgsH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "common_voice = DatasetDict()\n",
        "\n",
        "common_voice_train = load_dataset(\"fsicoli/common_voice_17_0\", \"en\", split=\"train\")\n",
        "common_voice_test = load_dataset(\"fsicoli/common_voice_17_0\", \"en\", split=\"test\")\n",
        "\n",
        "print(common_voice)"
      ],
      "metadata": {
        "id": "fYlxS9PSg3HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ECAPA encoding\n",
        "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\")\n",
        "signal = common_voice_train[0][\"audio\"][\"array\"]\n",
        "# fs = common_voice_train[0][\"audio\"][\"sampling_rate\"]\n",
        "embeddings = classifier.encode_batch(torch.tensor(signal))\n",
        "\n",
        "## Whisper Encoding\n",
        "model = WhisperModel.from_pretrained(\"openai/whisper-base\")\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\"openai/whisper-base\")\n",
        "\n",
        "inputs = feature_extractor(common_voice_train[0][\"audio\"][\"array\"], return_tensors=\"pt\")\n",
        "input_features = inputs.input_features\n",
        "decoder_input_ids = torch.tensor([[1, 1]]) * model.config.decoder_start_token_id\n",
        "last_hidden_state = model(input_features, decoder_input_ids=decoder_input_ids).encoder_last_hidden_state\n",
        "list(last_hidden_state.shape)"
      ],
      "metadata": {
        "id": "BEnpfJ7dhL_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFP5lUMNuj0W"
      },
      "outputs": [],
      "source": [
        "class SpeechModel(nn.Module):\n",
        "    def __init__(self, whisper_model, ecapa_model):\n",
        "        super(SpeechModel, self).__init__()\n",
        "        self.whisper_encoder = whisper_model.encoder\n",
        "        self.ecapa_encoder = ecapa_model.encoder\n",
        "\n",
        "        # Define downsampling layers\n",
        "        self.whisper_downsample = nn.Conv1d(...)\n",
        "        self.ecapa_downsample = nn.Conv1d(...)\n",
        "\n",
        "        # Define Transformer layers\n",
        "        self.transformer_encoder = nn.TransformerEncoderLayer(...)\n",
        "        self.transformer_decoder = nn.TransformerDecoderLayer(...)\n",
        "\n",
        "        # Define prediction heads\n",
        "        self.next_word_prediction_head = nn.Linear(...)\n",
        "        self.speaker_recognition_head = nn.Linear(...)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass for whisper branch\n",
        "        whisper_embedding = self.whisper_encoder(x)\n",
        "        downsampled_whisper = self.whisper_downsample(whisper_embedding)\n",
        "\n",
        "        # Forward pass for ECAPA branch\n",
        "        ecapa_embedding = self.ecapa_encoder(x)\n",
        "        downsampled_ecapa = self.ecapa_downsample(ecapa_embedding)\n",
        "\n",
        "        # Concatenate downscaled embeddings\n",
        "        concatenated_embeddings = torch.cat((downsampled_whisper, downsampled_ecapa), dim=1)\n",
        "\n",
        "        # Transformer layers\n",
        "        transformer_output = self.transformer_encoder(concatenated_embeddings)\n",
        "\n",
        "        # Task-specific heads\n",
        "        next_word_prediction = self.next_word_prediction_head(transformer_output)\n",
        "        speaker_recognition = self.speaker_recognition_head(transformer_output)\n",
        "\n",
        "        return next_word_prediction, speaker_recognition\n",
        "\n",
        "# Define model\n",
        "whisper_model = OpenAIWhisperEncoder(...)\n",
        "ecapa_model = ECAPATDNNModel(...)\n",
        "model = SpeechModel(whisper_model, ecapa_model)\n",
        "\n",
        "# Define loss functions\n",
        "next_word_loss_function = nn.CrossEntropyLoss()\n",
        "speaker_recognition_loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define data preprocessing\n",
        "transform = Compose([preprocess_function])\n",
        "\n",
        "# Load dataset\n",
        "dataset = CommonVoiceDataset(root_dir='path_to_commonvoice_dataset', transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        inputs, targets = batch\n",
        "        next_word_prediction, speaker_recognition = model(inputs)\n",
        "\n",
        "        # Calculate loss\n",
        "        next_word_loss = next_word_loss_function(next_word_prediction, targets)\n",
        "        # Calculate speaker recognition loss\n",
        "        speaker_recognition_loss = speaker_recognition_loss_function(speaker_recognition, speaker_labels)\n",
        "\n",
        "        total_loss = next_word_loss + speaker_recognition_loss\n",
        "\n",
        "        # Backpropagation\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n"
      ]
    }
  ]
}